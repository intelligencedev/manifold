<!doctype html>
<html lang="en" data-page="chat">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Singularity UI</title>
  <link rel="stylesheet" href="/static/templates/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
  <style>
    /* Avatar camera viewport */
    #avatarPane { display:flex; justify-content:center; }
    #avatarPane .avatar-window { width:256px; height:256px; overflow:hidden; position:relative; border-radius:12px; background:#111; box-shadow:0 0 4px rgba(0,0,0,0.4) inset; }
    #avatarPane .avatar-window img.agent-avatar { position:absolute; top:0; left:0; user-select:none; pointer-events:none; }
  </style>
</head>
<body data-theme="dark">
  <header class="site-header">
    <div class="logo">intelligence.dev</div>
  </header>
  <main class="layout">
    <div class="col col-left">
      <!-- reserved for navigation / workspace (future) -->
    </div>
    <div class="col col-middle">
      <section id="chat" class="panel">
        <div class="panel-header">Conversation</div>
        <div id="chatPane" class="messages" aria-live="polite" aria-label="Chat transcript"></div>
      </section>
      <div class="composer-wrapper">
        <div class="composer-shell" id="composer">
          <input id="promptInput" type="text" aria-label="Prompt" placeholder="Ask anything about your data, tools, or code..." autocomplete="off" />
          <button id="submitBtn" type="button">â–¶ Run</button>
        </div>
      </div>
    </div>
    <div class="col col-right">
      <aside id="avatar" class="panel">
        <div class="panel-header">Project Manager</div>
        <div id="avatarPane">
          <div class="avatar-window" data-window-width="256" data-window-height="400">
            <img src="/assets/smiling.png" alt="Current Working Agent" class="agent-avatar" data-shake-amplitude="1" data-shake-speed="1" />
          </div>
        </div>
      </aside>
      <aside id="tools" class="panel">
        <div class="panel-header">Tool Activity</div>
        <div id="toolsPane" class="tool-events" aria-live="polite" aria-label="Tool events">No tool activity yet.</div>
      </aside>
    </div>
  </main>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script>
// Camera shake with fixed viewport window + crossfade API
(()=>{
  const windowEl = document.querySelector('#avatarPane .avatar-window')
  const img = windowEl?.querySelector('img.agent-avatar')
  if (!windowEl || !img) return
  const amplitude = parseFloat(img.dataset.shakeAmplitude || '16')
  const speed = parseFloat(img.dataset.shakeSpeed || '1')
  const freqX = [0.9, 2.2, 4.7]
  const freqY = [1.1, 2.0, 3.8]
  const weights = [0.6, 0.3, 0.1]
  const phasesX = freqX.map(()=>Math.random()*Math.PI*2)
  const phasesY = freqY.map(()=>Math.random()*Math.PI*2)
  function sample(t){
    t *= speed
    let nx=0, ny=0
    for(let i=0;i<3;i++){ nx += weights[i]*Math.sin(2*Math.PI*freqX[i]*t + phasesX[i]); ny += weights[i]*Math.sin(2*Math.PI*freqY[i]*t + phasesY[i]); }
    return [nx*amplitude, ny*amplitude]
  }
  function sizeImage(image){
    const ww = parseInt(windowEl.dataset.windowWidth || windowEl.clientWidth || 256, 10)
    const wh = parseInt(windowEl.dataset.windowHeight || windowEl.clientHeight || 256, 10)
    windowEl.style.width = ww + 'px'
    windowEl.style.height = wh + 'px'
    const nw = image.naturalWidth || ww
    const nh = image.naturalHeight || wh
    const scale = Math.max((ww+2*amplitude)/nw, (wh+2*amplitude)/nh)
    const targetW = nw * scale
    const targetH = nh * scale
    image.style.width = targetW + 'px'
    image.style.height = targetH + 'px'
    const baseX = (ww - targetW)/2
    const baseY = (wh - targetH)/2
    image.dataset._baseX = baseX
    image.dataset._baseY = baseY
  }
  if (img.complete) sizeImage(img); else img.addEventListener('load', ()=>sizeImage(img))
  window.addEventListener('resize', ()=>sizeImage(img))
  let running = true
  const start = performance.now()
  function loop(now){
    if(!running) return
    const t = (now-start)/1000
    const [ox, oy] = sample(t)
    const baseX = parseFloat(img.dataset._baseX||'0')
    const baseY = parseFloat(img.dataset._baseY||'0')
    img.style.transform = `translate(${(baseX+ox).toFixed(2)}px, ${(baseY+oy).toFixed(2)}px)`
    requestAnimationFrame(loop)
  }
  requestAnimationFrame(loop)
  document.addEventListener('visibilitychange', ()=>{ running = !document.hidden; if (running) requestAnimationFrame(loop) })
  window.setAvatarImage = function(src, fadeMs=400){
    const current = windowEl.querySelector('img.agent-avatar')
    const next = new Image()
    next.src = src
    next.alt = current?.alt || 'Agent'
    next.className = current?.className || 'agent-avatar'
    next.dataset.shakeAmplitude = current?.dataset.shakeAmplitude || String(amplitude)
    next.dataset.shakeSpeed = current?.dataset.shakeSpeed || String(speed)
    next.style.position = 'absolute'
    next.style.top = '0'; next.style.left = '0'
    next.style.opacity = '0'
    next.style.transition = `opacity ${fadeMs}ms ease`
    windowEl.appendChild(next)
    next.addEventListener('load', ()=>{
      sizeImage(next)
      requestAnimationFrame(()=>{ next.style.opacity = '1' })
      setTimeout(()=>{ current?.remove() }, fadeMs+40)
    })
  }
})()

// Helper: append message to chat pane (renders markdown for agent)
function appendMessage(kind, text, raw=false) {
  const chat = document.getElementById('chatPane')
  const el = document.createElement('div')
  const content = document.createElement('div')
  const timestamp = document.createElement('div')
  timestamp.className = 'timestamp'
  timestamp.textContent = new Date().toLocaleTimeString()
  if (kind === 'user') {
    el.className = 'msg user'
    content.textContent = text
    el.appendChild(content)
    el.appendChild(timestamp)
  } else if (kind === 'agent') {
    el.className = 'msg agent'
    el.dataset.rawMarkdown = text || '' // Store raw markdown for streaming updates
    if (raw) {
      content.textContent = text
    } else {
      content.innerHTML = marked.parse(text || '')
    }
    el.appendChild(content)
    el.appendChild(timestamp)
  } else if (kind === 'info') {
    el.className = 'msg info'
    content.textContent = text
    el.appendChild(content)
    el.appendChild(timestamp)
  }
  chat.appendChild(el)
  chat.scrollTop = chat.scrollHeight
}

function appendToolEvent(title, content) {
  const pane = document.getElementById('toolsPane')
  // If first time, clear default text
  if (pane.textContent.trim() === 'No tool activity yet.') pane.textContent = ''
  const wrapper = document.createElement('div')
  wrapper.className = 'tool-block'
  const h = document.createElement('h3')
  h.textContent = title
  const pre = document.createElement('pre')
  pre.textContent = content
  wrapper.appendChild(h)
  wrapper.appendChild(pre)
  pane.appendChild(wrapper)
  pane.scrollTop = pane.scrollHeight
}

async function submitPrompt(prompt) {
  appendMessage('user', prompt)
  const backend = '/api/prompt'

  // Try SSE first by requesting Accept: text/event-stream
  const sseRes = await fetch(backend, {
    method: 'POST', headers: {'Content-Type':'application/json', 'Accept':'text/event-stream'},
    body: JSON.stringify({prompt})
  })

  const ct = sseRes.headers.get('content-type') || ''
  if (sseRes.status >= 400) {
    let txt
    try { txt = await sseRes.text() } catch { txt = '' }
    appendMessage('agent', `Error (${sseRes.status} ${sseRes.statusText}) calling /api/prompt.\n${txt || '(no body)'}\nHint: Make sure the web UI server (cmd/webui) is running and not conflicting with agentd on the same port. If you opened index.html directly from the file system, start the web UI server instead.`, true)
    return
  }

  if (ct.includes('text/event-stream')) {
    // Stream with streaming parser
    const reader = sseRes.body.getReader()
    const dec = new TextDecoder()
    let buf = ''
    appendMessage('agent', '') // placeholder for streaming content
    while (true) {
      const { value, done } = await reader.read()
      if (done) break
      buf += dec.decode(value, {stream: true})
      // SSE parsing: events separated by double newline
      let idx
      while ((idx = buf.indexOf('\n\n')) !== -1) {
        const raw = buf.slice(0, idx).trim()
        buf = buf.slice(idx+2)
        // Each line in raw starts with "data: " optionally
        const lines = raw.split(/\r?\n/)
        lines.forEach(line=>{
          if (line.startsWith('data:')) {
            const payload = line.slice(5).trim()
            // Expect JSON payloads with {type: 'delta'|'tool'|'final', data: '...'}
            try {
              const obj = JSON.parse(payload)
              if (obj.type === 'delta') {
                // Append to last agent message
                const chat = document.getElementById('chatPane')
                const last = chat.lastElementChild
                if (last && last.dataset.rawMarkdown !== undefined) {
                  // Append to raw markdown and re-render
                  if (last.dataset.rawMarkdown === '') {
                    // First delta - trim leading whitespace
                    last.dataset.rawMarkdown = obj.data.trimStart()
                  } else {
                    last.dataset.rawMarkdown += obj.data
                  }
                  const contentDiv = last.querySelector('div');
                  if (contentDiv) {
                    contentDiv.innerHTML = marked.parse(last.dataset.rawMarkdown);
                  }
                  chat.scrollTop = chat.scrollHeight
                }
              } else if (obj.type === 'tool') {
                appendToolEvent(obj.title || 'Tool', obj.data || '')
              } else if (obj.type === 'final') {
                // replace last element with final rendered markdown
                const chat = document.getElementById('chatPane')
                const last = chat.lastElementChild
                if (last && last.dataset.rawMarkdown !== undefined) {
                  last.dataset.rawMarkdown = obj.data || ''
                  const contentDiv = last.querySelector('div');
                  if (contentDiv) {
                    contentDiv.innerHTML = marked.parse(last.dataset.rawMarkdown);
                  }
                }
              }
            } catch (e) {
              // Not JSON, append raw
              appendMessage('agent', payload, false)
            }
          }
        })
      }
    }
    // process any remaining buffer
    if (buf.trim() !== '') {
      try {
        const obj = JSON.parse(buf.trim())
        if (obj.type === 'final') appendMessage('agent', obj.data || '', false)
      } catch (e) {
        appendMessage('agent', buf, true)
      }
    }
    return
  }

  // Fallback: non-streaming
  const ctype = sseRes.headers.get('content-type') || ''
  if (ctype.includes('application/json')) {
    const j = await sseRes.json()
    if (j.result) appendMessage('agent', j.result, false)
    else appendMessage('agent', JSON.stringify(j), true)
  } else {
    const txt = await sseRes.text()
    appendMessage('agent', txt, true)
  }
}

document.getElementById('submitBtn').addEventListener('click', async () => {
  const input = document.getElementById('promptInput')
  const v = input.value.trim()
  if (!v) return
  input.value = ''
  try {
    await submitPrompt(v)
  } catch (err) {
    appendMessage('agent', 'Error: ' + err.message, true)
  }
})

// Press Enter to submit
document.getElementById('promptInput').addEventListener('keydown', (e)=>{
  if (e.key === 'Enter') { e.preventDefault(); document.getElementById('submitBtn').click() }
})

// Theme toggle removed (single theme mode)
</script>
</body>
</html>
