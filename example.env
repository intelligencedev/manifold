# OpenAI Compatible API configuration
LLM_PROVIDER=openai
OPENAI_BASE_URL="https://api.openai.com/v1"
OPENAI_API_KEY="my_openai_api_key"
OPENAI_MODEL=gpt-5-mini
OPENAI_SUMMARY_URL="https://api.openai.com/v1"
OPENAI_SUMMARY_MODEL=gpt-5-nano
# Optional additional providers
# ANTHROPIC_API_KEY=""
# ANTHROPIC_MODEL=""
# ANTHROPIC_BASE_URL=""
# GOOGLE_LLM_API_KEY=""
# GOOGLE_LLM_MODEL="gemini-1.5-flash"
# GOOGLE_LLM_BASE_URL="https://generativelanguage.googleapis.com/"
TTS_BASE_URL="https://api.openai.com/v1/audio/speech"
TTS_MODEL="gpt-4o-mini-tts"
TTS_VOICE="alloy"

# Agent configuration
ENABLE_TOOLS=true
ALLOW_TOOLS=run_cli,apply_patch,llm_transform,describe_image,specialists_infer,web_fetch,mcp_duckduckgo_search
MAX_STEPS=1000
# MAX_TOOL_PARALLELISM controls concurrent tool execution (0=unbounded, 1=sequential, >1=capped)
# Default: 0 (unbounded parallelism)
MAX_TOOL_PARALLELISM=0
MAX_COMMAND_SECONDS=1200
OUTPUT_TRUNCATE_BYTES=128000

# Context Management
SUMMARY_ENABLED=true
# Optional: cap the context window used for chat-memory budgeting.
# Keeps the raw transcript short even for large-context models.
SUMMARY_CONTEXT_WINDOW_TOKENS=32000

# Minimum/maximum number of recent messages to keep in raw form.
# Older turns are rolled into the session summary.
SUMMARY_MIN_KEEP_LAST_MESSAGES=4
SUMMARY_MAX_KEEP_LAST_MESSAGES=12

# Reserve buffer for output tokens (reasoning models may need ~25000).
SUMMARY_RESERVE_BUFFER_TOKENS=25000

# Maximum tokens per summary chunk.
SUMMARY_MAX_SUMMARY_CHUNK_TOKENS=4096

# Embedding configuration
# Used by pgvector / qdrant and the vector search tool
EMBED_BASE_URL="https://api.openai.com/v1"
EMBED_MODEL="text-embedding-3-small"
EMBED_API_KEY="my_openai_api_key"
EMBED_API_HEADER="Authorization"
# Optional: additional headers as JSON or comma-separated key:value pairs
# Example JSON: EMBED_API_HEADERS='{"x-trace-id":"abc","x-algo":"v2"}'
# Example CSV:  EMBED_API_HEADERS="x-trace-id:abc,x-algo:v2"
EMBED_PATH="/v1/embeddings"
EMBED_TIMEOUT="30"

# Evolving Memory System (Search → Synthesis → Evolve)
# Based on https://arxiv.org/abs/2511.20857
# Requires embedding service configured above
EVOLVING_MEMORY_ENABLED=false
EVOLVING_MEMORY_MAX_SIZE=1000
EVOLVING_MEMORY_TOP_K=4
EVOLVING_MEMORY_WINDOW_SIZE=20
EVOLVING_MEMORY_ENABLE_RAG=true
EVOLVING_MEMORY_REMEM_ENABLED=false
EVOLVING_MEMORY_MAX_INNER_STEPS=5
EVOLVING_MEMORY_MODEL=gpt-4o-mini
# Smart pruning (advanced) - deduplication and relevance-based memory management
EVOLVING_MEMORY_ENABLE_SMART_PRUNE=false
EVOLVING_MEMORY_PRUNE_THRESHOLD=0.95
EVOLVING_MEMORY_RELEVANCE_DECAY=0.99
EVOLVING_MEMORY_MIN_RELEVANCE=0.1

# Security configuration
# Comma-separated list of binaries that are blocked from being run by the run_cli tool.
BLOCK_BINARIES=rm,sudo,chown,chmod,dd,mkfs,mount,umount

# Database connection string
DATABASE_URL="postgres://manifold:manifold@pg-manifold:5432/manifold?sslmode=disable"

# Mount Manifold project as its own working directory. 
# This can be any path you want the agents to use as their working directory.
WORKDIR="."

# Observability
# The service is not required and will just log errors if not available.
# We include it here as reference.
OTEL_SERVICE_NAME=manifold
SERVICE_VERSION=0.0.1
ENVIRONMENT=local
OTEL_EXPORTER_OTLP_ENDPOINT="localhost:4318"
LOG_PATH="manifold.log"
LOG_LEVEL=trace
LOG_PAYLOADS=true
CLICKHOUSE_DSN="http://default@clickhouse:8123?database=otel"
CLICKHOUSE_DATABASE="otel"
CLICKHOUSE_METRICS_TABLE="metrics_sum"
CLICKHOUSE_TIMESTAMP_COLUMN="TimeUnix"
CLICKHOUSE_VALUE_COLUMN="Value"
CLICKHOUSE_MODEL_ATTRIBUTE_KEY="llm.model"
CLICKHOUSE_PROMPT_METRIC_NAME="llm.prompt_tokens"
CLICKHOUSE_COMPLETION_METRIC_NAME="llm.completion_tokens"
CLICKHOUSE_LOOKBACK_HOURS=24
CLICKHOUSE_TIMEOUT_SECONDS=5

# SonarQube (local static analysis)
# Used by `make sonar` to authenticate and submit scans.
SONAR_HOST_PORT=19000
SONAR_PROJECT_KEY=manifold
SONAR_ADMIN_USER=admin
SONAR_ADMIN_PASSWORD="change_me"

# Playground API service
PLAYGROUND_ADDR=:8081
PLAYGROUND_DSN=postgres://manifold:manifold@pg-manifold:5432/manifold?sslmode=disable
PLAYGROUND_ARTIFACT_DIR=./tmp/playground-artifacts

# Used by the internal web_search tool
# Use mcp/duckduckgo as an alternative to searxng
# See config.yaml mcp section for more details
# SEARXNG_URL="..."

# Runtime timeouts (seconds). 0 disables that specific server-side deadline.
# AGENT_RUN_TIMEOUT_SECONDS applies to non-streaming agent operations (/agent/run final, /api/prompt non-stream, vision).
# STREAM_RUN_TIMEOUT_SECONDS applies to streaming SSE paths (/agent/run, /api/prompt with Accept: text/event-stream or ?stream=1).
# WORKFLOW_TIMEOUT_SECONDS applies to /agent/workflow and /agent/specialist dispatches.
# Fallback chain:
#   streaming: STREAM_RUN_TIMEOUT_SECONDS -> AGENT_RUN_TIMEOUT_SECONDS -> 300 (default)
#   non-stream: AGENT_RUN_TIMEOUT_SECONDS -> 120 (default)
#   workflow: WORKFLOW_TIMEOUT_SECONDS -> AGENT_RUN_TIMEOUT_SECONDS -> 120 (default)
AGENT_RUN_TIMEOUT_SECONDS=0
STREAM_RUN_TIMEOUT_SECONDS=0
WORKFLOW_TIMEOUT_SECONDS=0
# Projects Storage Configuration (Phase 0 - Feature Flags Only)
# Backend: "filesystem" (default, current behavior) | "s3" (future)
PROJECTS_BACKEND=filesystem
# Enable at-rest encryption for project files
PROJECTS_ENCRYPT=false
# Workspace mode: "legacy" (use project dir directly) | "ephemeral" (per-session copies, future)
PROJECTS_WORKSPACE_MODE=legacy
# Root directory for ephemeral workspaces (default: ${WORKDIR}/sandboxes)
# PROJECTS_WORKSPACE_ROOT="${WORKDIR}/sandboxes"
# TTL for ephemeral workspaces in seconds (default: 86400 = 24 hours)
PROJECTS_WORKSPACE_TTL_SECONDS=86400

# Encryption Key Provider Configuration (Phase 4 - Enterprise Encryption)
# Provider: "file" (default/legacy), "vault" (HashiCorp Vault Transit), "awskms" (AWS KMS)
# PROJECTS_ENCRYPTION_PROVIDER=file
# File-based key provider (legacy/dev mode - master key stored locally)
# PROJECTS_ENCRYPTION_FILE_KEYSTORE_PATH="${WORKDIR}/.keystore"

# HashiCorp Vault Transit configuration (enterprise)
# PROJECTS_ENCRYPTION_VAULT_ADDRESS="https://vault.example.com:8200"
# PROJECTS_ENCRYPTION_VAULT_TOKEN=""  # Prefer VAULT_TOKEN env var
# PROJECTS_ENCRYPTION_VAULT_KEY_NAME="manifold-kek"
# PROJECTS_ENCRYPTION_VAULT_MOUNT_PATH="transit"
# PROJECTS_ENCRYPTION_VAULT_NAMESPACE=""  # Vault Enterprise namespace
# PROJECTS_ENCRYPTION_VAULT_TLS_SKIP_VERIFY=false
# PROJECTS_ENCRYPTION_VAULT_TIMEOUT_SECONDS=30

# HashiCorp Vault dev mode (docker-compose) - for local testing
# Start with: docker-compose up -d vault vault-init
# VAULT_DEV_ROOT_TOKEN=dev-only-token
# VAULT_KEY_NAME=manifold-kek
# To enable Vault encryption in dev mode:
# PROJECTS_ENCRYPT=true
# PROJECTS_ENCRYPTION_PROVIDER=vault
# PROJECTS_ENCRYPTION_VAULT_ADDRESS="http://localhost:8200"
# VAULT_TOKEN=dev-only-token

# AWS KMS configuration (enterprise)
# PROJECTS_ENCRYPTION_AWSKMS_KEY_ID="arn:aws:kms:us-east-1:123456789:key/12345678-..."
# PROJECTS_ENCRYPTION_AWSKMS_REGION="us-east-1"  # Falls back to AWS_REGION env
# PROJECTS_ENCRYPTION_AWSKMS_ACCESS_KEY_ID=""  # Prefer IAM roles or AWS_ACCESS_KEY_ID env
# PROJECTS_ENCRYPTION_AWSKMS_SECRET_ACCESS_KEY=""  # Prefer IAM roles or AWS_SECRET_ACCESS_KEY env
# PROJECTS_ENCRYPTION_AWSKMS_ENDPOINT=""  # Custom endpoint for LocalStack

# S3/MinIO configuration for projects storage (used when PROJECTS_BACKEND=s3)
# MinIO admin credentials (also used by docker-compose minio-init)
# MINIO_ROOT_USER=minioadmin
# MINIO_ROOT_PASSWORD=minioadmin

# S3 client configuration
# PROJECTS_S3_ENDPOINT="http://localhost:9002"  # MinIO S3 API (host port from docker-compose)
# PROJECTS_S3_REGION="us-east-1"
# PROJECTS_S3_BUCKET="manifold-workspaces"
# PROJECTS_S3_PREFIX="workspaces"
# PROJECTS_S3_ACCESS_KEY="minioadmin"
# PROJECTS_S3_SECRET_KEY="minioadmin"
# PROJECTS_S3_USE_PATH_STYLE=true  # Required for MinIO
# PROJECTS_S3_TLS_INSECURE=false
# PROJECTS_S3_SSE_MODE="none"  # none | sse-s3 | sse-kms
# PROJECTS_S3_SSE_KMS_KEY_ID=""
