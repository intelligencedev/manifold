# ===================================================================
# Manifold Configuration with Environment Variable Support
# ===================================================================
#
# This configuration file contains default values for the Manifold application.
# All settings can be overridden at runtime using environment variables.
#
# ENVIRONMENT VARIABLE MAPPING:
# ----------------------------
# Environment variables are automatically mapped to YAML paths using this convention:
#
# 1. Prefix all variables with "MANIFOLD_"
# 2. Use UPPERCASE for all letters
# 3. Use underscore (_) to represent nesting in the YAML hierarchy
#
# Examples:
#   MANIFOLD_HOST=api.example.com             → host: 'api.example.com'
#   MANIFOLD_PORT=9000                        → port: 9000
#   MANIFOLD_DATABASE_CONNECTION_STRING=...   → database.connection_string: '...'
#   MANIFOLD_MCPSERVERS_GITHUB_COMMAND=docker → mcpservers.github.command: 'docker'
#
# VALUE TYPES:
# -----------
# The script automatically handles different value types:
#
# - Numbers:     MANIFOLD_PORT=8080                   → port: 8080
# - Booleans:    MANIFOLD_SINGLE_NODE_INSTANCE=false  → single_node_instance: false
# - Strings:     MANIFOLD_HOST=localhost              → host: 'localhost'
# - Null:        MANIFOLD_HF_TOKEN=null               → hf_token: null
# - JSON arrays: MANIFOLD_MCPSERVERS_GITHUB_ARGS='["run","--rm"]' 
#                → mcpservers.github.args: ["run","--rm"]
# - JSON objects: MANIFOLD_SOME_CONFIG='{"key":"value"}' 
#                → some.config: {"key":"value"}
#
# HOW IT WORKS:
# ------------
# At container startup, the process_config.sh script:
# 1. Copies this file to config.yaml
# 2. Finds all MANIFOLD_* environment variables
# 3. Maps them to their corresponding YAML paths
# 4. Updates the config.yaml file accordingly
#
# ===================================================================

# ===================================================================
# SERVER CONFIGURATION
# ===================================================================

# Server address and port
host: 'localhost'
port: 8080

# Storage path for models, database files, and other persistent data
data_path: '/data'

# ===================================================================
# RUNTIME CONFIGURATION
# ===================================================================

# When enabled, Manifold automatically runs llama-server instances for:
# - embeddings (port 32184)
# - reranker (port 32185)
# - completions (port 32186)
single_node_instance: true

# ===================================================================
# DATABASE CONFIGURATION
# ===================================================================

database:
  # PostgreSQL connection string with PGVector extension
  # Format: postgres://username:password@hostname:port/database?sslmode=disable
  connection_string: ""

# ===================================================================
# API TOKENS
# ===================================================================

# HuggingFace API token for accessing gated models
hf_token: ""

# Google Gemini API token
google_gemini_key: ""

# Anthropic API token (Claude models)
anthropic_key: ""

# ===================================================================
# LLM SERVICES CONFIGURATION
# ===================================================================

# Completions Service Configuration
# Handles generation of text completions based on input prompts
completions:
  # OpenAI-compatible API endpoint
  default_host: "http://127.0.0.1:32186/v1/chat/completions"
  # Model identifier to use for completions
  completions_model: 'gpt-4o'
  # API key for the completions service (if required)
  api_key: ""

# Embeddings Service Configuration
# Manages the creation of vector representations for text data
# NOTE: nomic-embed-text-1.5 will be spun up automatically by default with the settings below
embeddings:
  # OpenAI-compatible API endpoint
  host: "http://127.0.0.1:32184/v1/embeddings"
  # API key for the embeddings service (if required)
  api_key: ""
  # Vector dimensions for the embedding model
  dimensions: 768
  # Prefix added to document text before embedding
  embed_prefix: "search_document: "
  # Prefix added to query text before embedding
  search_prefix: "search_query: "

# Reranker Service Configuration
# Reorders search results to improve relevance
reranker:
  # OpenAI-compatible API endpoint
  host: "http://127.0.0.1:32185/v1/rerank"

# ===================================================================
# MCP SERVERS CONFIGURATION
# ===================================================================

# MCP (Model Control Protocol) servers provide Manifold with data access
mcpServers:
  # Manifold's built-in MCP server
  manifold:
    command: ./cmd/mcp-manifold/mcp-manifold
    args: []
    env: {}

  # Example GitHub MCP server (commented by default)
  # github:
  #   command: docker
  #   args:
  #     - run
  #     - -i
  #     - --rm
  #     - -e
  #     - GITHUB_PERSONAL_ACCESS_TOKEN
  #     - ghcr.io/github/github-mcp-server
  #   env:
  #     GITHUB_PERSONAL_ACCESS_TOKEN: ""