<!doctype html>
<html lang="en" data-page="chat">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Singularity UI</title>
  <link rel="stylesheet" href="/static/templates/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
  <style>
    /* Avatar camera viewport */
    #avatarPane { display:flex; justify-content:center; }
    #avatarPane .avatar-window { width:256px; height:256px; overflow:hidden; position:relative; background:#0a0a0d; box-shadow:0 0 10px rgba(0,0,0,0.8) inset, 0 0 12px rgba(0,0,0,0.7); border-radius:12px; }
    #avatarPane .avatar-window img.agent-avatar { position:absolute; top:0; left:0; user-select:none; pointer-events:none; image-rendering:pixelated; filter:contrast(1.18) saturate(1.25) brightness(1.05) drop-shadow(0 0 6px rgba(0,255,220,0.08)); }
    /* CRT layers */
    #avatarPane .avatar-window.crt .crt-layer { position:absolute; inset:0; pointer-events:none; }
    /* Phosphor RGB triads (very subtle) */
    #avatarPane .avatar-window.crt .crt-phosphor { z-index:2; opacity:0.22; background:
      repeating-linear-gradient(to right,
        rgba(255,0,0,0.55) 0px, rgba(255,0,0,0.55) 1px,
        rgba(0,255,0,0.55) 1px, rgba(0,255,0,0.55) 2px,
        rgba(0,140,255,0.55) 2px, rgba(0,140,255,0.55) 3px,
        rgba(0,0,0,0.2) 3px, rgba(0,0,0,0.2) 4px
      ); mix-blend-mode:color-dodge; }
    /* Stronger scanlines */
    #avatarPane .avatar-window.crt .crt-scanlines { z-index:3; background:
      repeating-linear-gradient(to bottom,
        rgba(255,255,255,0.18) 0px,
        rgba(255,255,255,0.18) 1px,
        rgba(0,0,0,0.55) 1px,
        rgba(0,0,0,0.55) 2px
      ); mix-blend-mode:overlay; animation:crt-scan-move 5s linear infinite; }
    /* Darker vignette & curvature */
    #avatarPane .avatar-window.crt .crt-mask { z-index:4; background:
      radial-gradient(ellipse at center, rgba(0,0,0,0) 50%, rgba(0,0,0,0.35) 80%, rgba(0,0,0,0.75) 100%),
      linear-gradient(to right, rgba(0,0,0,0.45), rgba(0,0,0,0) 25%, rgba(0,0,0,0) 75%, rgba(0,0,0,0.45));
      mix-blend-mode:multiply; }
    /* Stronger but still subtle flicker */
    #avatarPane .avatar-window.crt .crt-flicker { z-index:5; background:rgba(255,255,255,0.04); animation:crt-flicker 0.08s infinite steps(2,end); mix-blend-mode:screen; }
    #avatarPane .avatar-window.crt .agent-avatar { z-index:1; }
    #avatarPane .avatar-window.crt { position:relative; }
    @keyframes crt-scan-move { 0% { background-position-y:0; } 100% { background-position-y:256px; } }
    @keyframes crt-flicker { 0%, 100% { opacity:0.02; } 50% { opacity:0.08; } }
  </style>
</head>
<body data-theme="dark">
  <header class="site-header">
    <div class="logo">intelligence.dev</div>
  </header>
  <main class="layout">
    <div class="col col-left">
      <!-- reserved for navigation / workspace (future) -->
    </div>
    <div class="col col-middle">
      <section id="chat" class="panel">
        <div class="panel-header">Conversation</div>
        <div id="chatPane" class="messages" aria-live="polite" aria-label="Chat transcript"></div>
      </section>
      <div class="composer-wrapper">
        <div class="composer-shell" id="composer">
          <input id="promptInput" type="text" aria-label="Prompt" placeholder="Ask anything about your data, tools, or code..." autocomplete="off" />
          <button id="submitBtn" type="button">â–¶ Run</button>
        </div>
      </div>
    </div>
    <div class="col col-right">
      <aside id="avatar" class="panel">
        <div class="panel-header">Project Manager</div>
        <div id="avatarPane">
          <div class="avatar-window crt" data-window-width="256" data-window-height="400">
            <!-- Default looping avatar (listening state) -->
            <img src="/assets/listening.gif" alt="Current Working Agent" class="agent-avatar" data-shake-amplitude="1" data-shake-speed="1" />
            <div class="crt-layer crt-phosphor"></div>
            <div class="crt-layer crt-scanlines"></div>
            <div class="crt-layer crt-mask"></div>
            <div class="crt-layer crt-flicker"></div>
          </div>
        </div>
      </aside>
      <aside id="tools" class="panel">
        <div class="panel-header">Tool Activity</div>
        <div id="toolsPane" class="tool-events" aria-live="polite" aria-label="Tool events">No tool activity yet.</div>
      </aside>
    </div>
  </main>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script>
// Camera shake with fixed viewport window + crossfade API (persistent across swaps)
(()=>{
  const windowEl = document.querySelector('#avatarPane .avatar-window')
  let currentImg = windowEl?.querySelector('img.agent-avatar')
  if (!windowEl || !currentImg) return
  const amplitude = parseFloat(currentImg.dataset.shakeAmplitude || '16')
  const speed = parseFloat(currentImg.dataset.shakeSpeed || '1')
  const freqX = [0.9, 2.2, 4.7]
  const freqY = [1.1, 2.0, 3.8]
  const weights = [0.6, 0.3, 0.1]
  const phasesX = freqX.map(()=>Math.random()*Math.PI*2)
  const phasesY = freqY.map(()=>Math.random()*Math.PI*2)
  function sample(t){
    t *= speed
    let nx=0, ny=0
    for(let i=0;i<3;i++){ nx += weights[i]*Math.sin(2*Math.PI*freqX[i]*t + phasesX[i]); ny += weights[i]*Math.sin(2*Math.PI*freqY[i]*t + phasesY[i]); }
    return [nx*amplitude, ny*amplitude]
  }
  function sizeImage(image){
    if(!image) return
    const ww = parseInt(windowEl.dataset.windowWidth || windowEl.clientWidth || 256, 10)
    const wh = parseInt(windowEl.dataset.windowHeight || windowEl.clientHeight || 256, 10)
    windowEl.style.width = ww + 'px'
    windowEl.style.height = wh + 'px'
    const nw = image.naturalWidth || ww
    const nh = image.naturalHeight || wh
    const scale = Math.max((ww+2*amplitude)/nw, (wh+2*amplitude)/nh)
    const targetW = nw * scale
    const targetH = nh * scale
    image.style.width = targetW + 'px'
    image.style.height = targetH + 'px'
    const baseX = (ww - targetW)/2
    const baseY = (wh - targetH)/2
    image.dataset._baseX = baseX
    image.dataset._baseY = baseY
  }
  if (currentImg.complete) sizeImage(currentImg); else currentImg.addEventListener('load', ()=>sizeImage(currentImg))
  window.addEventListener('resize', ()=>sizeImage(currentImg))
  let running = true
  const start = performance.now()
  function loop(now){
    if(!running) return
    const t = (now-start)/1000
    const [ox, oy] = sample(t)
    if (currentImg) {
      const baseX = parseFloat(currentImg.dataset._baseX||'0')
      const baseY = parseFloat(currentImg.dataset._baseY||'0')
      currentImg.style.transform = `translate(${(baseX+ox).toFixed(2)}px, ${(baseY+oy).toFixed(2)}px)`
    }
    requestAnimationFrame(loop)
  }
  requestAnimationFrame(loop)
  document.addEventListener('visibilitychange', ()=>{ running = !document.hidden; if (running) requestAnimationFrame(loop) })
  window.setAvatarImage = function(src, fadeMs=400){
    const prev = currentImg
    const next = new Image()
    next.src = src
    next.alt = prev?.alt || 'Agent'
    next.className = prev?.className || 'agent-avatar'
    next.dataset.shakeAmplitude = prev?.dataset.shakeAmplitude || String(amplitude)
    next.dataset.shakeSpeed = prev?.dataset.shakeSpeed || String(speed)
    next.style.position = 'absolute'
    next.style.top = '0'; next.style.left = '0'
    next.style.opacity = '0'
    next.style.transition = `opacity ${fadeMs}ms ease`
    const firstOverlay = windowEl.querySelector('.crt-layer')
    if (firstOverlay) windowEl.insertBefore(next, firstOverlay); else windowEl.appendChild(next)
    next.addEventListener('load', ()=>{
      sizeImage(next)
      // Switch the shaking target to the new image immediately so effect persists
      currentImg = next
      requestAnimationFrame(()=>{ next.style.opacity = '1' })
      setTimeout(()=>{ prev?.remove() }, fadeMs+40)
    })
  }
})()

// Helper: append message to chat pane (renders markdown for agent)
function appendMessage(kind, text, raw=false) {
  const chat = document.getElementById('chatPane')
  const el = document.createElement('div')
  const content = document.createElement('div')
  const timestamp = document.createElement('div')
  timestamp.className = 'timestamp'
  timestamp.textContent = new Date().toLocaleTimeString()
  if (kind === 'user') {
    el.className = 'msg user'
    content.textContent = text
    el.appendChild(content)
    el.appendChild(timestamp)
  } else if (kind === 'agent') {
    el.className = 'msg agent'
    el.dataset.rawMarkdown = text || '' // Store raw markdown for streaming updates
    if (raw) {
      content.textContent = text
    } else {
      content.innerHTML = marked.parse(text || '')
    }
    el.appendChild(content)
    el.appendChild(timestamp)
  } else if (kind === 'info') {
    el.className = 'msg info'
    content.textContent = text
    el.appendChild(content)
    el.appendChild(timestamp)
  }
  chat.appendChild(el)
  chat.scrollTop = chat.scrollHeight
}

function appendToolEvent(title, content) {
  const pane = document.getElementById('toolsPane')
  // If first time, clear default text
  if (pane.textContent.trim() === 'No tool activity yet.') pane.textContent = ''
  const wrapper = document.createElement('div')
  wrapper.className = 'tool-block'
  const h = document.createElement('h3')
  h.textContent = title
  const pre = document.createElement('pre')
  pre.textContent = content
  wrapper.appendChild(h)
  wrapper.appendChild(pre)
  pane.appendChild(wrapper)
  pane.scrollTop = pane.scrollHeight
}

async function submitPrompt(prompt) {
  // Trigger avatar animation immediately when a prompt is submitted
  if (typeof window.playPromptAnimation === 'function') {
    window.playPromptAnimation()
  }
  appendMessage('user', prompt)
  const backend = '/api/prompt'

  // Try SSE first by requesting Accept: text/event-stream
  const sseRes = await fetch(backend, {
    method: 'POST', headers: {'Content-Type':'application/json', 'Accept':'text/event-stream'},
    body: JSON.stringify({prompt})
  })

  const ct = sseRes.headers.get('content-type') || ''
  if (sseRes.status >= 400) {
    let txt
    try { txt = await sseRes.text() } catch { txt = '' }
    appendMessage('agent', `Error (${sseRes.status} ${sseRes.statusText}) calling /api/prompt.\n${txt || '(no body)'}\nHint: Make sure the web UI server (cmd/webui) is running and not conflicting with agentd on the same port. If you opened index.html directly from the file system, start the web UI server instead.`, true)
    return
  }

  if (ct.includes('text/event-stream')) {
    // Stream with streaming parser
    const reader = sseRes.body.getReader()
    const dec = new TextDecoder()
    let buf = ''
    appendMessage('agent', '') // placeholder for streaming content
    while (true) {
      const { value, done } = await reader.read()
      if (done) break
      buf += dec.decode(value, {stream: true})
      // SSE parsing: events separated by double newline
      let idx
      while ((idx = buf.indexOf('\n\n')) !== -1) {
        const raw = buf.slice(0, idx).trim()
        buf = buf.slice(idx+2)
        // Each line in raw starts with "data: " optionally
        const lines = raw.split(/\r?\n/)
        lines.forEach(line=>{
          if (line.startsWith('data:')) {
            const payload = line.slice(5).trim()
            // Expect JSON payloads with {type: 'delta'|'tool'|'final', data: '...'}
            try {
              const obj = JSON.parse(payload)
              if (obj.type === 'delta') {
                // Append to last agent message
                const chat = document.getElementById('chatPane')
                const last = chat.lastElementChild
                if (last && last.dataset.rawMarkdown !== undefined) {
                  // Append to raw markdown and re-render
                  if (last.dataset.rawMarkdown === '') {
                    // First delta - trim leading whitespace
                    last.dataset.rawMarkdown = obj.data.trimStart()
                  } else {
                    last.dataset.rawMarkdown += obj.data
                  }
                  const contentDiv = last.querySelector('div');
                  if (contentDiv) {
                    contentDiv.innerHTML = marked.parse(last.dataset.rawMarkdown);
                  }
                  chat.scrollTop = chat.scrollHeight
                }
              } else if (obj.type === 'tool') {
                appendToolEvent(obj.title || 'Tool', obj.data || '')
              } else if (obj.type === 'final') {
                // replace last element with final rendered markdown
                const chat = document.getElementById('chatPane')
                const last = chat.lastElementChild
                if (last && last.dataset.rawMarkdown !== undefined) {
                  last.dataset.rawMarkdown = obj.data || ''
                  const contentDiv = last.querySelector('div');
                  if (contentDiv) {
                    contentDiv.innerHTML = marked.parse(last.dataset.rawMarkdown);
                  }
                }
              }
            } catch (e) {
              // Not JSON, append raw
              appendMessage('agent', payload, false)
            }
          }
        })
      }
    }
    // process any remaining buffer
    if (buf.trim() !== '') {
      try {
        const obj = JSON.parse(buf.trim())
        if (obj.type === 'final') appendMessage('agent', obj.data || '', false)
      } catch (e) {
        appendMessage('agent', buf, true)
      }
    }
    return
  }

  // Fallback: non-streaming
  const ctype = sseRes.headers.get('content-type') || ''
  if (ctype.includes('application/json')) {
    const j = await sseRes.json()
    if (j.result) appendMessage('agent', j.result, false)
    else appendMessage('agent', JSON.stringify(j), true)
  } else {
    const txt = await sseRes.text()
    appendMessage('agent', txt, true)
  }
}

document.getElementById('submitBtn').addEventListener('click', async () => {
  const input = document.getElementById('promptInput')
  const v = input.value.trim()
  if (!v) return
  input.value = ''
  try {
    await submitPrompt(v)
  } catch (err) {
    appendMessage('agent', 'Error: ' + err.message, true)
  }
})

// Press Enter to submit
document.getElementById('promptInput').addEventListener('keydown', (e)=>{
  if (e.key === 'Enter') { e.preventDefault(); document.getElementById('submitBtn').click() }
})

// Theme toggle removed (single theme mode)

// -------------------------------------------------------------
// Avatar Animation System
// Idle state: continuously cycle through listening*.gif variants, selecting a new one
// after the previous finishes a single loop (estimated via frame delays).
// Active (prompt) state: play a one-off reaction GIF (thinking/listening2/etc.) for one loop
// then return to idle cycle (not just a single default).\n
// -------------------------------------------------------------
;(()=>{
  // Idle pool (listening variants). If new listening*.gif files are added they can be appended here manually
  const IDLE_GIFS = [
    '/assets/listening.gif',
    '/assets/listening2.gif',
    '/assets/listening3.gif',
    '/assets/listening4.gif'
  ]
  // Prompt reaction pool (non-idle / expressive set)
  const PROMPT_GIFS = [
    '/assets/thinking.gif',
    '/assets/pensive.gif',
    '/assets/smiling.gif',
    '/assets/sad.gif'
  ].filter(Boolean)
  // Current operational mode
  let inPromptAnimation = false
  // Fallback duration per GIF if parsing fails (ms)
  const DEFAULT_DURATION = 2500
  // Cache of measured single-loop durations
  const gifDurations = {}
  let revertTimer = null
  let currentGif = null
  let idleTimer = null
  let lastIdleChoice = null

  async function measureGifOnce(url){
    if (gifDurations[url]) return gifDurations[url]
    try {
      const res = await fetch(url + '?cache=meta', {cache:'no-store'})
      const buf = await res.arrayBuffer()
      const bytes = new Uint8Array(buf)
      let total = 0
      for (let i=0; i < bytes.length - 9; i++) {
        // Graphic Control Extension: 21 F9 04 .. .. delay(lo) delay(hi)
        if (bytes[i]===0x21 && bytes[i+1]===0xF9 && bytes[i+2]===0x04) {
          const delayLo = bytes[i+4]
          const delayHi = bytes[i+5]
            // delay in hundredths of a second
          let delay = delayLo | (delayHi << 8)
          if (delay === 0) delay = 1 // some gifs put 0; treat as 10ms
          total += delay * 10 // ms
        }
      }
      if (total === 0) total = DEFAULT_DURATION
      gifDurations[url] = total
      return total
    } catch (e) {
      gifDurations[url] = DEFAULT_DURATION
      return DEFAULT_DURATION
    }
  }

  function pickRandom(list, exclude){
    if(!list.length) return null
    let filtered = list
    if (exclude) filtered = list.filter(x=>x!==exclude)
    if(!filtered.length) filtered = list
    return filtered[Math.floor(Math.random()*filtered.length)]
  }

  async function scheduleNextIdle(afterMs){
    if (idleTimer) clearTimeout(idleTimer)
    idleTimer = setTimeout(()=>{ runIdleCycle() }, afterMs)
  }

  async function runIdleCycle(){
    if (inPromptAnimation) return // paused during prompt reaction
    const choice = pickRandom(IDLE_GIFS, lastIdleChoice)
    if(!choice) return
    lastIdleChoice = choice
    currentGif = choice
    const duration = await measureGifOnce(choice)
    window.setAvatarImage(choice + '?idle=' + Date.now(), 220)
    scheduleNextIdle(Math.min(duration, 10000))
  }

  async function playPromptAnimation(){
    if(!window.setAvatarImage) return
    if (!PROMPT_GIFS.length) return
    inPromptAnimation = true
    if (revertTimer) { clearTimeout(revertTimer); revertTimer = null }
    if (idleTimer) { clearTimeout(idleTimer); idleTimer = null }
    const choice = pickRandom(PROMPT_GIFS)
    currentGif = choice
    const duration = await measureGifOnce(choice)
    window.setAvatarImage(choice + '?prompt=' + Date.now(), 160)
    revertTimer = setTimeout(()=>{
      if (currentGif === choice) {
        inPromptAnimation = false
        currentGif = null
        runIdleCycle() // resume idle cycle immediately
      }
      revertTimer = null
    }, Math.min(duration, 8000))
  }

  // Expose globally for submitPrompt hook
  window.playPromptAnimation = playPromptAnimation

  window.addEventListener('load', ()=>{
    // Start idle cycle (replace whatever initial avatar is after first loop)
    runIdleCycle()
  })
})()
</script>
</body>
</html>
