# Manifold Example Configuration

# Manifold Host
host: 'localhost'
port: 8080

# Manifold storage path: models, database files, etc
data_path: '~/.manifold'

# Database Configuration (PGVector)
database:
  connection_string: "postgres://pgadmin:yourpassword@localhost:5432/manifold?sslmode=disable"  # REPLACE with your actual credentials

# HuggingFace Token
hf_token: "..." 

# Anthropic API token
anthropic_key: "..."

# Default Completions Configuration - any openai api compatible backend - llama.cpp (llama-server), vllm, mlx_lm.server, etc
completions:
  default_host: "<my_openai_api_compatible_server>/v1/chat/completions"
  # OpenAI API compatible API key, not required for local servers unless configured on that server
  api_key: "my_api_key"

# Embeddings API Configuration
embeddings:
  host: "<my_openai_api_compatible_server>/v1/embeddings"
  # OpenAI API compatible API key, not required for local servers unless configured on that server
  api_key: "your_embeddings_api_key"
  embedding_vectors: 768 # Size of embedding vectors depending on model

# Reranker llama.cpp endpoint
reranker:
  host: "<my llama.cpp or other /v1/rerank endpoint>"


# OBSERVABILITY

# Jaeger endpoint for tracing. Actual Jaeger deployment not required but server will throw error. 
# Leave as-is unless you have a real Jaeger endpoint to configure
jaeger_host: 'localhost:16686'